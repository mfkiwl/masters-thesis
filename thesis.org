# -*- eval: (visual-line-mode t) -*-
#+TITLE: RTIC Scope — Real-Time Tracing Support for the RTIC RTOS Framework
#+AUTHOR: Viktor Sonesten
#+EMAIL: vikson-6@student.ltu.se
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [twocolumn]
#+options: toc:nil
#+latex_header: \usepackage{libertine}
#+latex_header: \usepackage{inconsolata}
#+latex_header: \usepackage[citestyle=authoryear-icomp,bibstyle=authoryear, hyperref=true,maxcitenames=3,url=true,backend=biber,natbib=true]{biblatex}
#+latex_header: \addbibresource{ref.bib}
#+latex_header: \usepackage{microtype}

# TODO typeset TODOS for easier reviewing (is this even possible? TODOs are mostly comments)
# TODO install and apply a grammar checker.

* Org setup
  #+begin_src emacs-lisp :result output :session :exports both
    (require 'ox-extra)
    (ox-extras-activate '(ignore-headlines))
  #+end_src

* *The Paper*                                                        :ignore:

# Make this a single paragraph; use unambiguous terms; aim for 250 words; 3-5 keywords.
#+begin_abstract
Here be an abstract...
#+end_abstract

** Introduction
# What are embedded systems, regulators, and how do they relate?
Embedded systems --- a unit combination of a central processing unit, system memory, and input/output peripheral devices --- serve a key role in the operation of systems with electronical components where computations must be made.
A prime examples of such systems are digital control systems which regulate one or more control quantities such that they adhere to designed characteristics.
Often the goal is to track a reference signal; such a control system is known as a regulator.
A regulator observes (either directly or by approximation) the internal states of a system under control via sensors and affect the system via actuators.
For example, one may wish to keep a rocket on a set path to reach orbit, or control the internals of a nuclear power plant to maximize electrical power output and keep the reactor in a safe state.

# On the real-time restrictions of control systems; exponential complexity phenomena.
A key design parameter of digital controllers is the sample rate: if too low or unconsistent, the controlled system will end up unstable. cite:franklin
The rocket may thus fly off course, or the nuclear reactor reach a meltdown.
This puts a real-time constrain on the digital controller which greatly limits how it can be implemented.
Further, a digital controller under implementation must be debugged so that the engineers can verify its correct operation.
This task grows exponentially in difficulty with as the number of system states, inputs, and outputs increase.
A similar phenomena is observed for embedded systems that have other tasks than to simply regulate[fn:2].

# The observer effect; data exfiltration.
Unfortunately, embedded systems are subject to the observer effect: to observe the internal state of a embedded system (i.e., system variables in memory) its operation must be affected.
# A proper implementation would not block on a serial write.
This observeration is often realized by exfiltrating data via serial communication which in the best case can be subject to bus contention and full output queues.
In a perfect implementation, the user application[fn:1] would only concern itself with its mainsake regulation prodecure and leave data exfiltration to a completely disjoint system, thus minimizing the observer effect and thus the effect on the underlying control system.

# ARM, tracing subsystem and possible exploitation.
ARM is an ubiquitous vendor for embedded systems with a number of sub-vendors (e.g. STMicroelectrics, NXP Semiconductors, Nordic Semiconductors).
The ARMv7-M standard offers debugging facilities that enables the developer to trace the system.
From ARM's documentation, "Trace refers to the process of capturing data that illustrates how the components in a design are operating, executing, and performing". cite:arm-cortex-learn
Additionally, "[Trace generation is] almost entirely non-invasive. [Trace generation] does not influence the wider system".
This trace facility allows an event-based monitoring of
- interrupt enters and exits (tracing of hardware tasks, e.g. the main control loop);
- Read and write access to in-memory adress spaces (system state variables, software tasks); and
- comparator matches, among other features.
The generated trace is then exfiltrated via serial using a packet protocol, henceforth referred to as the "trace stream".
This trace stream (with system-external collection) is thus a suitable candidate for exploitation to realize a control system with minimal observer effect.

# Less work, more sleep.
Further, with non-invasive trace generation, minimal code must be executed in the user application, allowing a shorter duty-cycle of the controlling program.
With a decreased duty-cycle, the system can be put to sleep longer, and thus conserve energy.

# On real-time implementation restictions, embedded implementation difficulties in general. Enter RTIC.
# TODO generalize? Mention that RTOS helps, present SRP/RTIC in background?
The development of embedded system in general is a difficult one.
In comparison to general-purpose computers, where one often need not worry about resource limitations, embedded systems are constrained in all manners such that costs can be minimized for their non-general applications.
# No rich OS; no two embedded platforms are the same.
An embedded developer seldom have access to a rich operating systems (OS) --- a Linux-based distibution, for example --- which offers general-purpose facilities based upon dynamic allocations and a common environment to simplity implementation.
Embedded platforms usually differ significantly, and porting an implementation to another platform is no small task.
This compares to general-purpose computers where a program written on one computer can be executed on another.
# Side effects and priority inversions.
Embedded platforms are much more subject to side-effects where peripherals are operated by writing data to memory-mapped registers.
Of certain importance is the problem of priority inversions, where a task of lower priority executes instead of a higher prioritized task because of implementation error.
In summary, it is easy to put an embedded system in an incorrect or unknown state.
# Enter RTIC.
In order to lighten the implementation burden one may employ Real-Time Interrupt-driven Concurrency (RTIC), a real-time OS (RTOS) developed at Luleå Technical University based on the extensively studied Stack Resource Policy (SRP), which mitigates priority inversions while also offering determinant scheduling of future tasks and message-passing between tasks.
# TODO refer to rauk
RTIC also lends itself to static analysis by help of external tools, further lighening the overhead of an embedded implementation.

# Project aim
The aim of this thesis is thus to employ and extend upon RTIC with a toolset to leverage ARM's non-intrusive tracing facilites whilst requiring minimal overhead for then end-user developer, greatly lightening the burden to implement digital control systems.
The resulting toolset will be employed to implement a regulator for a non-trivial dynamic system, and the ergonomics of the toolset evaluated.

# TODO throw in some stats on how much ARM is used in industy?
# TODO "mission-critical systems are thus implemented in worst case scenario, doing more work than necessary, because it is easier to analyze"? Do we have a source on this?

 # The vendor ARM...
 # - ITM
 # - tracing (debugging) without affecting user application.
 # - nothing need to be done from the user applicaiton.
 # - watch adresses are impl. by monitoring user application from an otherwise disjoint system (what about clock?)
 # - software tasks require user application effect, but RTIC Scope aims for minimal
 # - hardware tasks are traced via interrupts, but no effect on user application.

*** Background
This section goes over the theory, tools, and hardware features utilized in order to develop RTIC Scope.

**** Real-Time Interrupt-driven Concurrency (RTIC)
 RTIC (cite:rtic) is a real-time operating system (RTOS) based on the stack resource policy (cite:baker90) for task scheduling written in the Rust programming language.

***** Rust
****** TODO refer to Tjäder's thesis when it comes to Rust?
***** RTIC syntax and features
**** ARM Hardware facilities
***** Breakpoints and watchpoints
***** Tracing
 RTIC supports the ARM Cortex-M4 family of microprocessor core units (MCUs) which, in turn, offer asynchronous debug facilites for real-time tracing support (cite:arm-rm, §C).
 Of chief interest are
 - DWT, :: Data Watchpoint and Trace (cite:arm-rm, §C1.8): contains program counter and address comparators that signal on a match; and
 - ITM, :: Intrumentation Trace Macrocell (cite:arm-rm, §C1.7): trace information generator in the form of packets; multiplexes trace information from other sources (e.g. DWT).

 # Ref. does not say that ITM is real-time.
 Tracing is the ability to analyse the behavior of an embedded system in real-time without significantly affecting the user application, known as non-intrusive debugging.
 Proper application of tracing allows the developer to verify the behavior of an embedded system.

 ITM is realized in practise by communicating between the embedded system and the analysing system with a packet protocol. (cite:arm-rm, Appendix D4)

 # This does not fit in the background
 If the embedded system has the capability, tracing data may be buffered locally before it is transferred to an external system.
 The information can also be captured by monitoring a serial pin.
***** TODO refer to [[*Theory and Methodology]] for further details
      We only want to cover the basics here in the background.

*** Motivation
 Debugging the user application running on an MCU is an integral part of an embedded work-flow.
 Thus, the more debugging facilities that are readily available to the end-user of an RTOS, the better.
 More so if proper usage of such facilities --- which are commonly non-trivial on embedded systems --- is abstracted.
 However, care must be taken when utilizing debugging features on an embedded target as it should not significantly affect the user application, lest real-time properties will differ between a debug and release environment.

 # TODO Talk about RTIC and its increasing usage
 # TODO We want to make it very simple for the end user to trace an application, lookup "batteries included" definition.

*** Problem definition
This thesis explores the possibility of developing a toolset (RTIC Scope) that enables an RTIC application developer to gain non-invasive insight into an RTIC application.
This is done by exploiting the trace generation sub-system (DWT and ITM) of the ARMv7-M platform and capturing the generated trace stream on a host system for analysis (via ETB or TPIU).
The captured trace stream must be decoded, timestamped, and associated to tasks and resources defined in the RTIC application before being presented to the user.
RTIC Scope shall enable the developer to observe the execution and state of the RTIC application in real-time, but also record the trace stream for port-mortem/offline analysis.

*** Delimitations
In order to focus on the delivery of a robust tracing toolset with proper implementation and documentations the scope of this thesis have been limited.
These limits are enumerated below.
1. The number of possible approaches to present the execution and state of an RTIC application to an end-user is virtually infinite.
   For this reason RTIC Scope shall make it easy to develop frontends that extend the tool for any end-user's needs by exposing an backend-frontend API.
   In order to offer a starting point for future frontends a barebones reference CLI frontend will be developed as a proof-of-concept and for debugging purposes.
2. The work of this thesis will not stray from the ITM specification. ETM and other Coresight features (except for ETB), for example, will not be investigated.
3. No benchmarks will be done for the host-side tools created during this thesis because there are no other tools of this kind that applies to RTIC.
4. This thesis documents the development and implementation of RTIC Scope version 0.3. Any work made or planned beyond this release is considered as future work.
5. RTIC Scope v0.3 targets RTIC version 0.6.
6. RTIC Scope v0.3 only supports the ARM Cortex-M platform.

Following these limits allows time to ultimately yield a documented toolset that minimizes the friction of further development on the toolset by other parties.

*** Previous work
The implementation of RTIC Scope stands of the shoulders of countless developers that have enabled the implementation of the toolset within the frame of this thesis.
Of certain note are
- ~cortex-m~ :: that enable low-level access to Cortex-M processors;
- ~probe-rs~ :: an extensible embedded debugging toolkit;
- ~rtic-syntax~ :: RTIC meta language parser library; and
- ~itm~ (version 0.3) and ~itm-tools~ :: library and tools for analyzing ITM traces.

For a full list of dependant crates used by RTIC Scope, execute
#+begin_src shell
  $ cargo install cargo-tree
  $ git clone https://github.com/rtic-scope/cargo-rtic-scope.git && cd cargo-rtic-scope
  $ cargo tree
#+end_src

*** Contributions
The realization of such a toolset is a collection of crates that constitute the RTIC Scope project:
- ~cargo-rtic-scope~ :: a cargo subcommand that acts as host-side daemon: it
  - records raw trace data;
  - associates it to timestamped RTIC tasks, relative to target boot;
  - serializes this resolved trace to a file on disk and to any frontends; and
  - echoes any messages a frontend writes to =stderr=.
- ~rtic-scope-frontend-dummy~ :: a reference frontend implementation that simply prints timestamped RTIC tasks to =stderr=.
- ~rtic-scope-api~ :: the API implemented by ~cargo-rtic-scope~ an any frontend.
- ~cortex-m-rtic-trace~ :: an auxilliary target-side crate that properly configures the ITM/DWT/TPIU units.

Internally, ~cargo-rtic-scope~ relies on the ~itm~ crate --- also developed as part of this thesis --- to decode the ITM packet protocol generated by the target to manageable Rust structures.
Because of its more general nature and detachment from RTIC Scope it is not part of the project itself.

Aside from these novel crates, the following patches hav been submitted upstream in order to add functionality to upstream crates (listed in no particular order):
# TODO use latex escape for proper italics when / is must be italics also
# TODO convert to references
- probe-rs/probe-rs ::
  - /Reintroduce ~CargoOptions~ in ~mod common_options~/: https://github.com/probe-rs/probe-rs/pull/760;
  - /arm: enable exception trace on ~setup_swv~/: https://github.com/probe-rs/probe-rs/pull/758;
  - /cargo: bump bitvec/: https://github.com/probe-rs/probe-rs/pull/757;
  - /arm=/=itm: doc fields, enable global timestamps/: https://github.com/probe-rs/probe-rs/pull/728;
  - /Add generic probe=/=session logic from cargo-flash/: https://github.com/probe-rs/probe-rs/pull/723;
  - /deprecate internal ITM=/=DWT packet decoder in favour of itm-decode/: https://github.com/probe-rs/probe-rs/pull/564;
- rust-embedded/cortex-m ::
  - /scb: derive serde, Hash, PartialOrd for VectActive behind gates/: https://github.com/rust-embedded/cortex-m/pull/363;
  - /Implement various interfaces for trace configuration/: https://github.com/rust-embedded/cortex-m/pull/342;
- rust-embedded/itm ::
  - /replace crate with itm-decode/: https://github.com/rust-embedded/itm/pull/41;
- rtic-rs/rtic-syntax ::
  - /improve error string if parse_binds is not set/: https://github.com/rtic-rs/rtic-syntax/pull/47.
- rtic-rs/cortex-m-rtic ::
  - /book=/=migration=/=v5: update init signature, fix example syntax/: https://github.com/rtic-rs/cortex-m-rtic/pull/480;
  - /book: detail import resolving for 0.6 migration/: https://github.com/rtic-rs/cortex-m-rtic/pull/479;
  - /book: update outdated required init signature/: https://github.com/rtic-rs/cortex-m-rtic/pull/478.

*** Related work
# TODO convert to references
Some toolsets similar to RTIC Scope were already available before the start of this thesis, namely:
- orbuculum :: https://github.com/orbcode/orbuculum, an ARM Cortex-M trace stream demuxer and post-processor;
- Percepio Tracealyzer :: https://percepio.com/tracealyzer/, proprietary visual trace diagnostic tool that supports a multitude of platforms and RTOSs.

Neither of the tools support RTIC, nor have any inspiration been taken from them during the development of RTIC Scope.

*** TODO Outline
 This paper is structured as follows
 - [[Introduction]] :: provides an introduction to Rust, RTIC, ARM hardware peripherals of interest, and the RTIC Scope project.
 - [[Previous work]] :: presents work previously done in the same domain, which this thesis and RTIC Scope builds upon.
 - [[Related work]] :: presents some tools similar to the features of RTIC Scope.
 - [[Theory]] :: covers the exploited ARM peripherals in detail, and what information is required to associate trace data to RTIC tasks.
 - [[Implementation]] ::
 - [[Results]] ::
 - [[Discussion]] ::
 - [[Conclusions]] ::
 - [[Future work]] ::
 - Appendices ::
** TODO Method
This section summarizes the protocols, hardware peripherals, and software tools utilized in RTIC Scope.
For sake of brevity, this section is not exhaustive.
For more information on each component, refer to the respective documentation.

 # Sections [[*Instrumentation Trace Macrocell (ITM)]]--[[*Trace Port Interface Unit (TPIU)]] detail the peripherals used to generate the packet stream intercepted by RTIC Scope.
 # Section [[*RTIC]] detail the RTOS which the target application is expected to be written in, and how its metadata is extracted for use in RTIC Scope.

*** RTIC
**** Hardware tasks
  Hardware tasks are regular Rust functions that are bound to a hardware interrupt.
  When this interrupt is made pending in hardware, the task function executes.
  An example hardware task is declared via
  #+name: rtic-hw-task-example
  #+begin_src rust
    #[app]
    mod app {
        #[task(bound = EXTI0)]
        fn foo(_ctx: foo::Context) {
            // ...
        }
    }
  #+end_src
  With this declaration, =foo= will be executed when ~EXTI0~ is made pending in hardware.
  After =foo= returns, the interrupt has been handled and ~EXTI0~ is no longer pending.

**** Tracing hardware tasks
  Hardware tasks are exclusively bound to singular hardware interrupts.
  Because of this, whenever an interrupt handler executes (and thus the bound hardware task), an =ExceptionTrace { exception, function }= packet is emitted, where =exception= is the exception number as an integer and =function= is the action context of the exception: an exception is either entered, exited, or returned.

**** Resolving hardware task names
  =exception= is a number from (cite:arm-rm; Table B1-4), the external interrupt subset of which is modelled by =PAC::Interrupt=.
  This =Interrupt= enum is used by RTIC.
  To associate an =ExceptionTrace= to an RTIC task one must find
  - which hardware interrupt a task is bound to; and
  - what interrupt number this hardware interrupt is associated with.

  For the first issue, as seen in [[rtic-hw-task-example]], the bound hardware interrupt is declared in the source code.
  Associating task name to hardware interrupt can thus be done by parsing the source code.
  This can be done via ~rtic-syntax~ [fn:rtic-syntax].

  Finding the hardware interrupt from the interrupt number is a more involved process, even though the information needed is readily available in =PAC::Interrupt=.
  Because Rust does not support reflection it is not possible to inspect different =PAC= types in a single executable.
  The only approach available for resolving is some =Ident -> u8= function.
  There are multiple approaches for how such a function can be implemented.
  They are below enumerated and considered:
  - Parsing the source code of the different =PAC::Interrupt= structures: such a structure can be declared via
    #+begin_src rust
      #[repr(u8)]
      enum Interrupt {
          EXTI0 = 6,
          EXTI1 = 7,
          // ...
      }
    #+end_src
    It is then possible to download the crate source and parse this structure similar to the RTIC application.
    Fortunately, as this crate is generated by ~svd2rust~ and it is in the interests of its developers to generate as simple code as possible, the right-hand side of the =Interrupt= variants are always integer literals.
    These can trivially be converted to the wanted =u8= type.
    The problem thus minimizes to finding the =enum Interrupt= structure in he crate.
    The one "clue" given us to this end is the PAC in the =device= argument in the =rtic::app= macro.
    For example, if an RTIC application is declared with =#[app(divice = stm32f4::stm32f401)]=, it is likely that the =enum Interrupt= structure can be found in some ~/stm32f4/stm32f401/mod.rs~ source file.
    Alternativly, it may also be inlined in a single source file, say ~lib.rs~:
    #+begin_src rust
      mod stm32 {
          mod stm32f401 {
              #[repr(u8)]
              enum Interrupt {
                  // ...
              }
          }
      }
    #+end_src
    The host application could support a range of PAC structures to ultimately find the =Interrupt= structure.
  - Dynamically build, load, and call an adhoc cdylib crate that exposes =[Ident -> u8]= functions: All =PAC::Interrupt= structures implement the =bare_metal::Nr= trait.
    As the name implies, it allow us to call, for example =PAC::Interrupt::EXTI0.nr()= to get the interrupt number of =EXTI0=.
    This trait can be exploited.
    For the set of bounds that is parsed from an RTIC application:
    1. Parse the value of the =rtic::app= macro =device= argument into a =first::second= structure, where =second= is optional.
       For example, if an application is declared via =#[app(device = stm32f4::stm32f401)]=, =stm32f4= is mapped to =first=; =stm32f401= to =second=.

       It is here assumed that =first= is the crate that contains the =enum Interrupt= structure;
       =second= is the required crate feature if specified; and that the =enum Interrupt= is available under =first::second::Interrupt=.
    2. Create a cdylib[fn:cdylib] crate in a temporary directory that depends on =first= with the feature =second= (if specified).
    3. For each bind, generate a function that maps the bind to its interrupt numbers. For example, if the bind is =EXTI0=, generate
       #+begin_src rust
         #[no_mangle]
         pub extern fn EXTI0() -> u8 {
             first::second::Interrupt::EXTI0.nr()
         }
       #+end_src
    4. Build the crate using ~cargo~. [fn:cargo]
    5. Dynamically load the generated shared object file.
    6. For each bind, find the associated =extern fn() -> u8= symbol from the bind name, and call the function.
    7. Collect the bind names and associated interrupt numbers into a =<Ident, u8>= map.

  With the above approaches, we would have a mapping from RTIC task names to their bound hardware interrupt, and a mapping from hardware interrupt name to the interrupt number.
  Consequently, we would have a mapping from interrupt number to RTIC task name.
  Thus, an =ExceptionTrace= can then readibly be associated with a RTIC hardware task.
  These proposed procedures must be repeated once per application and PAC crate used.
  Of course, caching can be utilized to minimize the number of repeated steps.

  While both approaches can be used for the implementation of a =Ident -> u8= function, and both depend on the underlying PAC, they depend on different PAC structure: the source parsing approach depends on the lexical structure of the PAC's source code; and the cdylib approach on the parsed structure of the crate (that is, instead of parsing the source code ourselves, we leave that task to Rust itself).
  Additionally, multiple different lexical structures can map to the same parsed structure; if ~svd2rust~ decides on a lexical change, the host application would have to be changed also.
  It is then understood that the cdylib approach presents the smallest problem when implementing our wanted =Ident -> u8=, and is thus chosen as the best approach.

**** Software tasks
  Software tasks are also regular Rust functions that are bound to hardware interrupts, but the bound hardware interrupt is not exclusively associated to the task in question: a single hardware interrupt can be associated with multiple software tasks.
  For this reason, the used hardware interrupt is considered a "dispatcher".

  An example software task is declared via
  #+begin_src rust
    #[app(dispatchers = [EXTI0])]
    mod app {
        #[task]
        fn bar(_ctx: bar::Context) {
            // ...
        }
    }
  #+end_src

  In difference to hardware tasks, software tasks can be scheduled by software.

**** Tracing software tasks
  Because the implementation of software tasks utilizes hardware interrupts, software tasks can be traced in the same manner as hardware tasks if it is ensured that every dispatcher only manages a single software task.
  However, in practise a dispatcher commonly manager multiple software tasks.
  An emitted =ExceptionTrace= thus tells us when a dispatcher starts, but not which software task it dispatches.

**** Resolving software task names
  The =ExceptionTrace= does not give us all the information we need.
  Instead, a [[#DWT]] unit can be employed to emit =DataTraceValue= packets on software task enter and exit.
  Via this approach, each software task is given a unique ID and code is injected (either by the =rtic::app= macro or by the end-user themselves) to write this unique ID at the start and end of the software task.
  The emitted =DataTraceValue= packets are then analysed by the host application, which maintains a state of which software task is currenly running.[fn:dwt-running-bit]
  The RTIC application source is then parsed to associate =DataTraceValue= payloads back to their software tasks.

  In comparison to hardware tasks, which are practically traced for free, software tasks can be traced at the cost of a few register writes and a dedicated DWT unit.

*** Hardware peripherals
# DWT -> ITM -> TPIU.
RTIC Scope utilizes the /Data WatchPoint and Trace/ (DWT), /Intrumentation Trace Macrocell/ (ITM), and the /Trace Port Interface Unit/ (TPIU) peripherals for on-target trace generation and trace extraction.
The DWT and ITM peripherals are sources of ITM packets which are forwarded to the TPIU for device exfiltration.
These peripherals are summarized below.

**** Data Watchpoint and Trace (DWT)
# Summarize DWT functionality exploited in RTIC Scope
The DWT peripheral provides the core of the utilized hardware tracing functionality by generating trace packets when (for example)
- a configured range of data is read or written (known as data tracing) by help of 15 hardware comparators at maximum; and
- whenever the processor enters an exception handler and returns from it (known as exception tracing).
Thus, tracing of hardware-bound RTIC tasks is enabled by intercepting exception trace packets, and software tasks are traced by writing a unique task identifier to a monitored address and intercepting the data trace packets.

# DWT comparators /can/ trace RTIC resources, but its complex
RTIC resources can theoretically also be traced by help of DWT comparators, but such as approach would be relatively complex.
A data trace value packet contains up to one word (32 bits) of information.
If the RTIC resources fits within a word only a single packet must be intercepted.
However, a more common praxis is the usage of non-primitive resources which have differing sizes between an debug and optimized build of the target application.
The more common case is then the need to intercept multiple data trace value packets from which the resources must be reconstructed.
The need to emit more packets increases the possibility of DWT buffer overflows events, during which the packet is dropped and an overflow packet is generated instead.
Of note is that the overflow packet does not contain any information on what caused the overflow.
Assuming that all packets can be send and intercepted without buffer overflows, the issue of reconstucting the most-likely non-primitive data structures remain.
This requires DWARF information and is a project on its own.

All the packets generated by the DWT unit are sent to the ITM unit and then forwarded to the TPIU.

For more information on the DWT unit, refer to [[pdf:~/exjobb/docs/DDI0403E_d_armv7m_arm.pdf::719++1.07][DDI0403E_d_armv7m_arm.pdf: Page 719]].

# XXX the DWT output buffer status cannot be queried

# TODO DWT packets are known as hardware event packets

**** Instrumentation Trace Macrocell (ITM)
# Summarize ITM functionality
The ITM unit is of an auxilliary nature; it has three functions:
- the multiplexing of hardware event packets from the DWT unit with its own instrumentation packets which are then forwarded to the TPIU;
- control and generation of timestamp packets; and
- a memory-mapped register interface that allows logging of arbitrary data via a maximum of 256 stimulus registers.

# Summarize timestamp packets
Timestamp packets are appended to a set of non-timestamp packets that occur at a common timestamp and come in two forms: global and local.
# TODO when exactly is the time counting started?
Global timestamps are absolute and starts counting at the boot of the target device.
Local timestamps are relative to the last local timestamp and resets its count when a new one is generated.
An up-to-date absolute timestamp can be calculated by applying all local timestamp values upon the last global timestamp.
For example, if a global timestamp with the value $10$ is emitted after which two local timestamps with the respective values of $3$ and $4$ are emitted, an up-to-date absolute timestamp is calculated via $10 + 3 + 4 = 17$.
Local timestamps also contain information on the relationship between the local timestamp generation and the corresponding trace packets. The timestamp can be
- synchronous to the generated packets: the timestamp is the counter value when the non-timestamp packets were generated;
- delayed relative to the packets: the timestamp is the counter value when the timestamp packet was generated (the local timestamp value corresponding to the non-timestamp packet generation event is thus unknown, but must be between the previous and current local timestamp value);
- delayed relative to the associated event: synchronous to the generated packets, but the packets themselves were delayed because of other trace output packets; or
- delayed relative to the packets and associated event: a combination of the last two conditions.

# TODO explain what clock drives the global timestamp clock (P710)
# TODO document sync packets (P712)
# TODO document arbitration between packets from different sources (P713)

# TODO Instrumentation packets and RTIC resource tracing
# 32b per stim register, each has a FIFOREADY bit, each instrumentation packet contains at max 4B = 32b
# port number, 0-31

# XXX ITM stims has its own output buffer not related to the DWT output buffer, the status of the ITM output buffer can be queried via FIFOREADY in ITM_STIMx

# TODO add an example figure how a collection of back-to-back trace packets may look like. Timestamp is last in the chain

For more information on the ITM unit, refer to [[pdf:~/exjobb/docs/DDI0403E_d_armv7m_arm.pdf::709++1.07][DDI0403E_d_armv7m_arm.pdf: Page 709]]. For more information on global and local timestamps, refer to P710.

**** Trace Port Interface Unit (TPIU)
# Summarize TPIU functionality
The TPIU provides external visibility of the trace packet stream by serializing...

by serializing these over a set of exposed hardware pins or via the MCU programmer unit (depending on target platform).
Depending on the platform, these can be GPIO pins which can be configured in parallel mode by use of multiple pins or a singular GPIO pin for an asynchronous port.

# Embedded Trace Buffer (ETB), SWO, or parallel trace port

For more information on the TPIU, refer to [[pdf:~/exjobb/docs/DDI0403E_d_armv7m_arm.pdf::750++1.07][DDI0403E_d_armv7m_arm.pdf: Page 750]].

# TODO recreate Fig. C1-1 from [[pdf:~/exjobb/thesis/docs/DDI0403E_d_armv7m_arm.pdf::713++0.00][DDI0403E_d_armv7m_arm.pdf: Page 713]] without ETM component.

# XXX The combination of the DWT and ITM packet stream and an asynchronous Serial Wire Output (SWO) is called a Serial Wire Viewer (SWV)

*** Decoding the ITM packet stream
Before the trace stream can be processed, the serialized stream must be decoded into workable Rust structures.
This is done via /itm-decode/ which
1. pattern matches the packet header;
2. checks if the payload is of the expected size; and
3. constructs the relevant structure.
If the packet cannot be decoded, an error structure is instead constructed, detailing why the packet is incorrect.
An erroneous packet can be received if the connection between embedded target and host system is not configured properly (e.g. baud-rate mismatch), or if the target itself does not adhere to the ITM packet protocol specification.

Additionally, itm-decode generates an absolute ISO timestamp from the relative timestamps in the protocol from a starting point and groups the relevant packets to this timestamp.

# TODO include a figure of the control flow
# TODO include reference to the library.

** TODO Implementation
# go over frontends and backends, sources and sinks
RTIC Scope is constructed in a single-input, multiple-output manner:
trace data will be read from a single /source/, and forwarded one or more /sinks/ when information has been recovered.
RTIC Scope will continue to run as long as the source can be read from, and there is at least one sink available.

# detail how information is recovered, translation maps

** TODO Results
*** Using RTIC Scope
From an end-user perspective RTIC Scope offers a "batteries-included" toolset that enables great insight into a target RTIC applications,
provided that a small set of limitations are adhered to and specific metadata is added to the application crate in question.
To install RTIC Scope, an end-user executes
#+begin_src shell
  $ cargo install cargo-rtic-scope
  $ cargo install rtic-scope-frontend-dummy
#+end_src
and adds the following metadata to their RTIC application's ~Cargo.toml~:
#+begin_src toml
  [package.metadata.rtic-scope]
  # necessary information for RTIC metadata recovery
  pac_name = "stm32f4"
  pac_features = ["stm32f401"]
  pac_version = "0.13"
  interrupt_path = "stm32f4::stm32f401::Interrupt"

  # ITM/DWT/TPIU parameters
  tpiu_freq = 16000000
  tpiu_baud = 115200
  dwt_enter_id = 1
  dwt_exit_id = 2
  lts_prescaler = 1

  # Whether it is expected that the target generates packets that do not adhere to the ITM standard.
  # For debugging purposes.
  expect_malformed = true
#+end_src

# TODO document cortex-m-rtic-trace usage

*** Tracing overhead with RTIC Scope
[[https://developer.arm.com/documentation/102119/0200/Can-trace-capture-affect-a-system-][ARM's /Understanding Trace/, $7]], states that:
#+begin_quote
Except for the power that is consumed by the system trace components,
trace is almost entirely non-invasive. This means that performing trace
generation and collection does not influence the wider system.
#+end_quote

The target-side code of RTIC Scope itself has a negligible performance impact during execution:
- the ITM/DWT/TPIU units need only be configured once in =#[init]= or during some other preparatory stage; and
- when software tasks are traced, a =u8= variable write must be done when entering and exiting the task.

The performance of the host-side ~cargo-rtic-scope~ and ~rtic-scope-frontend-dummy~ have not been measured.

# TODO DWT unit consumption

** TODO Discussion
*** Tracing overhead
*** TODO Conclusions
*** TODO Future work

  \printbibliography
  \appendices

** TODO Application to a non-linear control system
 # The results of the R7014E-alike course

* Footnotes

[fn:2] Additional tasks could for example include: handling firmware updates over the air. # TODO more examples?
[fn:1] The program that executes on the embedded system when initialization has concluded. In some contexts also referred to as the "main loop".

[fn:cargo-cdylibs] See
https://docs.rs/cargo/0.52.0/cargo/core/compiler/struct.Compilation.html#structfield.cdylibs.

[fn:cdylib] A cdylib crate is a crate that specifies =crate_type = ["cdylib"]=.
Upon building the crate a dynamic library (a shared object file) that targets the stable C ABI is generated.
Additionally, it is trivial to find the file location of cdylibs with cargo[fn:cargo-cdylibs].
This is not the case with dylibs that instead target the unstable Rust ABI.
The only way to generate a shared object file is by building a dylib or a cdylib.

[fn:dwt-running-bit] Alternatively, one bit in the =DataTraceValue= payload can denote whether a task was entered or exited.

[fn:cargo] See https://crates.io/crates/cargo.

[fn:rtic-syntax] See https://crates.io/crates/rtic-syntax.

[fn:decoder] Based upon the existing works of ~itm-tools~[fn:itm-tools].

[fn:memory-lanes] https://github.com/rtic-rs/rfcs/issues/31 discusses the RTIC-abstraction of RTT and similar peripherals to "memory lanes".

[fn:itm-tools] See https://github.com/japaric/itm-tools.

[fn:cli] Command-line interface.

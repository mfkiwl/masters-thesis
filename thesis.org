# -*- eval: (visual-line-mode t) -*-
#+TITLE: RTIC Scope — Real-Time Tracing Support for the RTIC RTOS Framework
#+AUTHOR: Viktor Vilhelm Sonesten
#+EMAIL: vikson-6@student.ltu.se
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [twocolumn]
#+options: toc:nil
#+latex_header: \usepackage{libertine}
#+latex_header: \usepackage{inconsolata}
#+latex_header: \usepackage[citestyle=authoryear-icomp,bibstyle=authoryear, hyperref=true,maxcitenames=3,url=true,backend=biber,natbib=true]{biblatex}
#+latex_header: \addbibresource{ref.bib}
#+latex_header: \usepackage{microtype}

# TODO typeset TODOS for easier reviewing (is this even possible? TODOs are mostly comments)
# TODO install and apply a grammar checker.
# TODO use glossary everywhere <https://www.overleaf.com/learn/latex/Glossaries>
# TODO +NAME all listings?
# TODO cite any mentioned crates.
# TODO call an RTIC app just that, or firmware, throughout.

* Org setup
  #+begin_src emacs-lisp :result output :session :exports both
    (require 'ox-extra)
    (ox-extras-activate '(ignore-headlines))
  #+end_src

* *The Paper*                                                        :ignore:

# Make this a single paragraph; use unambiguous terms; aim for 250 words; 3-5 keywords.
#+begin_abstract
Here be an abstract...
#+end_abstract

** Introduction
# What are embedded systems, regulators, and how do they relate?
Embedded systems --- a unit combination of a central processing unit, system memory, and input/output peripheral devices --- serve a key role in the operation of systems with electronical components where computations must be made.
A prime examples of such systems are digital control systems which regulate one or more control quantities such that they adhere to designed characteristics.
Often the goal is to track a reference signal; such a control system is known as a regulator.
A regulator observes (either directly or by approximation) the internal states of a system under control via sensors and affect the system via actuators.
For example, one may wish to keep a rocket on a set path to reach orbit, or control the internals of a nuclear power plant to maximize electrical power output and keep the reactor in a safe state.

# On the real-time restrictions of control systems; exponential complexity phenomena.
A key design parameter of digital controllers is the sample rate: if too low or unconsistent, the controlled system will end up unstable. cite:franklin
The rocket may thus fly off course, or the nuclear reactor reach a meltdown.
This puts a real-time constrain on the digital controller which greatly limits how it can be implemented.
Further, a digital controller under implementation must be debugged so that the engineers can verify its correct operation.
This task grows exponentially in difficulty with as the number of system states, inputs, and outputs increase.
A similar phenomena is observed for embedded systems that have other tasks than to simply regulate[fn:2].

# The observer effect; data exfiltration.
Unfortunately, embedded systems are subject to the observer effect: to observe the internal state of a embedded system (i.e., system variables in memory) its operation must be affected.
# A proper implementation would not block on a serial write.
This observeration is often realized by exfiltrating data via serial communication which in the best case can be subject to bus contention and full output queues.
In a perfect implementation, the user application[fn:1] would only concern itself with its mainsake regulation prodecure and leave data exfiltration to a completely disjoint system, thus minimizing the observer effect and thus the effect on the underlying control system.

# ARM, tracing subsystem and possible exploitation.
ARM is an ubiquitous vendor for embedded systems with a number of sub-vendors (e.g. STMicroelectrics, NXP Semiconductors, Nordic Semiconductors).
The ARMv7-M standard offers debugging facilities that enables the developer to trace the system.
From ARM's documentation, "Trace refers to the process of capturing data that illustrates how the components in a design are operating, executing, and performing". cite:arm-cortex-learn
Additionally, "[Trace generation is] almost entirely non-invasive. [Trace generation] does not influence the wider system".
This trace facility allows an event-based monitoring of
- interrupt enters and exits (tracing of hardware tasks, e.g. the main control loop);
- Read and write access to in-memory adress spaces (system state variables, software tasks); and
- comparator matches, among other features.
The generated trace is then exfiltrated via serial using a packet protocol, henceforth referred to as the "trace stream".
This trace stream (with system-external collection) is thus a suitable candidate for exploitation to realize a control system with minimal observer effect.

# Less work, more sleep.
Further, with non-invasive trace generation, minimal code must be executed in the user application, allowing a shorter duty-cycle of the controlling program.
With a decreased duty-cycle, the system can be put to sleep longer, and thus conserve energy.

# On real-time implementation restictions, embedded implementation difficulties in general. Enter RTIC.
# TODO generalize? Mention that RTOS helps, present SRP/RTIC in background?
The development of embedded system in general is a difficult one.
In comparison to general-purpose computers, where one often need not worry about resource limitations, embedded systems are constrained in all manners such that costs can be minimized for their non-general applications.
# No rich OS; no two embedded platforms are the same.
An embedded developer seldom have access to a rich operating systems (OS) --- a Linux-based distibution, for example --- which offers general-purpose facilities based upon dynamic allocations and a common environment to simplity implementation.
Embedded platforms usually differ significantly, and porting an implementation to another platform is no small task.
This compares to general-purpose computers where a program written on one computer can be executed on another.
# Side effects and priority inversions.
Embedded platforms are much more subject to side-effects where peripherals are operated by writing data to memory-mapped registers.
Of certain importance is the problem of priority inversions, where a task of lower priority executes instead of a higher prioritized task because of implementation error.
In summary, it is easy to put an embedded system in an incorrect or unknown state.
# Enter RTIC.
In order to lighten the implementation burden one may employ Real-Time Interrupt-driven Concurrency (RTIC), a real-time OS (RTOS) developed at Luleå Technical University based on the extensively studied Stack Resource Policy (SRP), which mitigates priority inversions while also offering determinant scheduling of future tasks and message-passing between tasks.
# TODO refer to rauk
RTIC also lends itself to static analysis by help of external tools, further lighening the overhead of an embedded implementation.

# Project aim
The aim of this thesis is thus to employ and extend upon RTIC with a toolset to leverage ARM's non-intrusive tracing facilites whilst requiring minimal overhead for then end-user developer, greatly lightening the burden to implement digital control systems.
The resulting toolset will be employed to implement a regulator for a non-trivial dynamic system, and the ergonomics of the toolset evaluated.

# TODO throw in some stats on how much ARM is used in industy?
# TODO "mission-critical systems are thus implemented in worst case scenario, doing more work than necessary, because it is easier to analyze"? Do we have a source on this?

 # The vendor ARM...
 # - ITM
 # - tracing (debugging) without affecting user application.
 # - nothing need to be done from the user applicaiton.
 # - watch adresses are impl. by monitoring user application from an otherwise disjoint system (what about clock?)
 # - software tasks require user application effect, but RTIC Scope aims for minimal
 # - hardware tasks are traced via interrupts, but no effect on user application.

*** Background
This section goes over the theory, tools, and hardware features utilized in order to develop RTIC Scope.

**** ARMv7-M debug facilities
This section summarizes the ITM packet protocol and the hardware peripherals responsible for its generation and device exfiltration.
For sake of brevity this section is not exhaustible.
For more information on each component, refer to the respective technical reference documentation.

***** Hardware peripherals
# DWT -> ITM -> TPIU/ETB.
RTIC Scope utilizes the /Data WatchPoint and Trace/ (DWT), /Intrumentation Trace Macrocell/ (ITM), and the /Trace Port Interface Unit/ (TPIU) peripherals for on-target trace generation and trace extraction.
The DWT and ITM peripherals are sources of ITM packets which are forwarded to the TPIU for device exfiltration.
These peripherals are summarized below.

****** Data Watchpoint and Trace (DWT)
# Summarize DWT functionality exploited in RTIC Scope
The DWT peripheral provides the core of the utilized hardware tracing functionality by generating trace packets when (for example)
- a configured range of data is read or written (known as data tracing) by help of 15 hardware comparators at maximum; and
- whenever the processor enters an exception handler and returns from it (known as exception tracing).
Thus, tracing of hardware-bound RTIC tasks is enabled by intercepting exception trace packets, and software tasks are traced by writing a unique task identifier to a monitored address and intercepting the data trace packets.

# DWT comparators /can/ trace RTIC resources, but its complex
RTIC resources can theoretically also be traced by help of DWT comparators, but such as approach would be relatively complex.
A data trace value packet contains up to one word (32 bits) of information.
If the RTIC resources fits within a word only a single packet must be intercepted.
However, a more common praxis is the usage of non-primitive resources which have differing sizes between an debug and optimized build of the target application.
The more common case is then the need to intercept multiple data trace value packets from which the resources must be reconstructed.
The need to emit more packets increases the possibility of DWT buffer overflows events, during which the packet is dropped and an overflow packet is generated instead.
Of note is that the overflow packet does not contain any information on what caused the overflow.
Assuming that all packets can be send and intercepted without buffer overflows, the issue of reconstucting the most-likely non-primitive data structures remain.
This requires DWARF information and is a project on its own.

All the packets generated by the DWT unit are sent to the ITM unit and then forwarded to the TPIU.

For more information on the DWT unit, refer to [[pdf:~/exjobb/docs/DDI0403E_d_armv7m_arm.pdf::719++1.07][DDI0403E_d_armv7m_arm.pdf: Page 719]].

# XXX the DWT output buffer status cannot be queried

# TODO DWT packets are known as hardware event packets

****** Instrumentation Trace Macrocell (ITM)
# Summarize ITM functionality
The ITM unit is of an auxilliary nature; it has three functions:
- the multiplexing of hardware event packets from the DWT unit with its own instrumentation packets which are then forwarded to the TPIU;
- control and generation of timestamp packets; and
- a memory-mapped register interface that allows logging of arbitrary data via a maximum of 256 stimulus registers.

# Summarize timestamp packets
Timestamp packets are appended to a set of non-timestamp packets that occur at a common timestamp and come in two forms: global and local.
# TODO when exactly is the time counting started?
Global timestamps are absolute and starts counting at the boot of the target device.
Local timestamps are relative to the last local timestamp and resets its count when a new one is generated.
An up-to-date absolute timestamp can be calculated by applying all local timestamp values upon the last global timestamp.
For example, if a global timestamp with the value $10$ is emitted after which two local timestamps with the respective values of $3$ and $4$ are emitted, an up-to-date absolute timestamp is calculated via $10 + 3 + 4 = 17$.
Local timestamps also contain information on the relationship between the local timestamp generation and the corresponding trace packets. The timestamp can be
- synchronous to the generated packets: the timestamp is the counter value when the non-timestamp packets were generated;
- delayed relative to the packets: the timestamp is the counter value when the timestamp packet was generated (the local timestamp value corresponding to the non-timestamp packet generation event is thus unknown, but must be between the previous and current local timestamp value);
- delayed relative to the associated event: synchronous to the generated packets, but the packets themselves were delayed because of other trace output packets; or
- delayed relative to the packets and associated event: a combination of the last two conditions.

# TODO explain what clock drives the global timestamp clock (P710)
# TODO document sync packets (P712)
# TODO document arbitration between packets from different sources (P713)

# TODO Instrumentation packets and RTIC resource tracing
# 32b per stim register, each has a FIFOREADY bit, each instrumentation packet contains at max 4B = 32b
# port number, 0-31

# XXX ITM stims has its own output buffer not related to the DWT output buffer, the status of the ITM output buffer can be queried via FIFOREADY in ITM_STIMx

# TODO add an example figure how a collection of back-to-back trace packets may look like. Timestamp is last in the chain

For more information on the ITM unit, refer to [[pdf:~/exjobb/docs/DDI0403E_d_armv7m_arm.pdf::709++1.07][DDI0403E_d_armv7m_arm.pdf: Page 709]]. For more information on global and local timestamps, refer to P710.

****** Trace Port Interface Unit (TPIU)
# Summarize TPIU functionality
The TPIU provides external visibility of the trace packet stream by serializing...

by serializing these over a set of exposed hardware pins or via the MCU programmer unit (depending on target platform).
Depending on the platform, these can be GPIO pins which can be configured in parallel mode by use of multiple pins or a singular GPIO pin for an asynchronous port.

# Embedded Trace Buffer (ETB), SWO, or parallel trace port

For more information on the TPIU, refer to [[pdf:~/exjobb/docs/DDI0403E_d_armv7m_arm.pdf::750++1.07][DDI0403E_d_armv7m_arm.pdf: Page 750]].

# TODO recreate Fig. C1-1 from [[pdf:~/exjobb/thesis/docs/DDI0403E_d_armv7m_arm.pdf::713++0.00][DDI0403E_d_armv7m_arm.pdf: Page 713]] without ETM component.

# XXX The combination of the DWT and ITM packet stream and an asynchronous Serial Wire Output (SWO) is called a Serial Wire Viewer (SWV)

****** TODO Embedded Trace Buffer (ETB)
***** TODO Tracing (Old), merge with the above?
RTIC supports the ARM Cortex-M4 family of microprocessor core units (MCUs) which, in turn, offer asynchronous debug facilites for real-time tracing support (cite:arm-rm, §C).
Of chief interest are
- DWT, :: Data Watchpoint and Trace (cite:arm-rm, §C1.8): contains program counter and address comparators that signal on a match; and
- ITM, :: Intrumentation Trace Macrocell (cite:arm-rm, §C1.7): trace information generator in the form of packets; multiplexes trace information from other sources (e.g. DWT).

  # Ref. does not say that ITM is real-time.
Tracing is the ability to analyse the behavior of an embedded system in real-time without significantly affecting the user application, known as non-intrusive debugging.
Proper application of tracing allows the developer to verify the behavior of an embedded system.

ITM is realized in practise by communicating between the embedded system and the analysing system with a packet protocol. (cite:arm-rm, Appendix D4)

# This does not fit in the background
If the embedded system has the capability, tracing data may be buffered locally before it is transferred to an external system.
The information can also be captured by monitoring a serial pin.

**** Real-Time Interrupt-driven Concurrency (RTIC)
***** TODO Device initialization
# explain how #[init] works
***** TODO The special idle task
# explain how #[idle] works, wfi, etc.

***** Hardware tasks
Hardware tasks are regular Rust functions that are bound to a hardware interrupt.
When this interrupt is made pending in hardware, the task function executes.
An example hardware task is declared via
#+name: rtic-hw-task-example
#+begin_src rust
  #[rtic::app]
  mod app {
      #[task(bound = EXTI0)]
      fn foo(_ctx: foo::Context) {
          // ...
      }
  }
#+end_src
With this declaration, =foo= will be executed when ~EXTI0~ is made pending in hardware.
  After =foo= returns, the interrupt has been handled and ~EXTI0~ is no longer pending.

***** Software tasks
  Software tasks are also regular Rust functions that are bound to hardware interrupts, but the bound hardware interrupt is not exclusively associated to the task in question: a single hardware interrupt can be associated with multiple software tasks.
  For this reason, the used hardware interrupt is considered a "dispatcher".

  An example software task is declared via
  #+begin_src rust
    #[rtic::app(dispatchers = [EXTI0])]
    mod app {
        #[task]
        fn bar(_ctx: bar::Context) {
            // ...
        }
    }
  #+end_src

  In difference to hardware tasks, software tasks can be scheduled by software.

**** Peripheral Access Crates (PACs)
# In implementation we need to explain how to enable tracing. We do this with a PAC generated by svd2rust. Better to cover it a bit

*** Motivation
 Debugging the user application running on an MCU is an integral part of an embedded work-flow.
 Thus, the more debugging facilities that are readily available to the end-user of an RTOS, the better.
 More so if proper usage of such facilities --- which are commonly non-trivial on embedded systems --- is abstracted.
 However, care must be taken when utilizing debugging features on an embedded target as it should not significantly affect the user application, lest real-time properties will differ between a debug and release environment.

 # TODO Talk about RTIC and its increasing usage
 # TODO We want to make it very simple for the end user to trace an application, lookup "batteries included" definition.

*** Problem definition
This thesis explores the possibility of developing a toolset (RTIC Scope) that enables an RTIC application developer to gain non-invasive insight into an RTIC application.
This is done by exploiting the trace generation sub-system (DWT and ITM) of the ARMv7-M platform and capturing the generated trace stream on a host system for analysis (via ETB or TPIU).
The captured trace stream must be decoded, timestamped, and associated to tasks and resources defined in the RTIC application before being presented to the user.
RTIC Scope shall enable the developer to observe the execution and state of the RTIC application in real-time, but also record the trace stream for port-mortem/offline analysis.

*** Delimitations
In order to focus on the delivery of a robust tracing toolset with proper implementation and documentations the scope of this thesis have been limited.
These limits are enumerated below.
1. The number of possible approaches to present the execution and state of an RTIC application to an end-user is virtually infinite.
   For this reason RTIC Scope shall make it easy to develop frontends that extend the tool for any end-user's needs by exposing an backend-frontend API.
   In order to offer a starting point for future frontends a barebones reference CLI frontend will be developed as a proof-of-concept and for debugging purposes.
2. The work of this thesis will not stray from the ITM specification. ETM and other Coresight features (except for ETB), for example, will not be investigated.
3. No benchmarks will be done for the host-side tools created during this thesis because there are no other tools of this kind that applies to RTIC.
4. This thesis documents the development and implementation of RTIC Scope version 0.3. Any work made or planned beyond this release is considered as future work.
5. RTIC Scope v0.3 targets RTIC version 0.6.
6. RTIC Scope v0.3 only supports the ARM Cortex-M platform.

Following these limits allows time to ultimately yield a documented toolset that minimizes the friction of further development on the toolset by other parties.

*** Previous work
The implementation of RTIC Scope stands of the shoulders of countless developers that have enabled the implementation of the toolset within the frame of this thesis.
Of certain note are
- ~cortex-m~ :: that enable low-level access to Cortex-M processors;
- ~probe-rs~ :: an extensible embedded debugging toolkit;
- ~rtic-syntax~ :: RTIC meta language parser library; and
- ~itm~ (version 0.3) and ~itm-tools~ :: library and tools for analyzing ITM traces.

For a full list of dependant crates used by RTIC Scope, execute
#+begin_src shell
  $ cargo install cargo-tree
  $ git clone https://github.com/rtic-scope/cargo-rtic-scope.git && cd cargo-rtic-scope
  $ cargo tree
#+end_src

*** Related work
# TODO convert to references
Some toolsets similar to RTIC Scope were already available before the start of this thesis, namely:
- orbuculum :: https://github.com/orbcode/orbuculum, an ARM Cortex-M trace stream demuxer and post-processor;
- Percepio Tracealyzer :: https://percepio.com/tracealyzer/, proprietary visual trace diagnostic tool that supports a multitude of platforms and RTOSs.

Neither of the tools support RTIC, nor have any inspiration been taken from them during the development of RTIC Scope.

*** Contributions
The realization of such a toolset is a collection of crates that constitute the RTIC Scope project:
- ~cargo-rtic-scope~ :: a cargo subcommand that acts as host-side daemon: it
  - records raw trace data;
  - associates it to timestamped RTIC tasks, relative to target boot;
  - serializes this resolved trace to a file on disk and to any frontends; and
  - echoes any messages a frontend writes to =stderr=.
- ~rtic-scope-frontend-dummy~ :: a reference frontend implementation that simply prints timestamped RTIC tasks to =stderr=.
- ~rtic-scope-api~ :: the API implemented by ~cargo-rtic-scope~ an any frontend.
- ~cortex-m-rtic-trace~ :: an auxilliary target-side crate that properly configures the ITM/DWT/TPIU units.

Internally, ~cargo-rtic-scope~ relies on the ~itm~ crate --- also developed as part of this thesis --- to decode the ITM packet protocol generated by the target to manageable Rust structures.
Because of its more general nature and detachment from RTIC Scope it is not part of the project itself.

Aside from these novel crates, the following patches hav been submitted upstream in order to add functionality to upstream crates (listed in no particular order):
# TODO use latex escape for proper italics when / is must be italics also
# TODO convert to references
- probe-rs/probe-rs ::
  - /Reintroduce ~CargoOptions~ in ~mod common_options~/: https://github.com/probe-rs/probe-rs/pull/760;
  - /arm: enable exception trace on ~setup_swv~/: https://github.com/probe-rs/probe-rs/pull/758;
  - /cargo: bump bitvec/: https://github.com/probe-rs/probe-rs/pull/757;
  - /arm=/=itm: doc fields, enable global timestamps/: https://github.com/probe-rs/probe-rs/pull/728;
  - /Add generic probe=/=session logic from cargo-flash/: https://github.com/probe-rs/probe-rs/pull/723;
  - /deprecate internal ITM=/=DWT packet decoder in favour of itm-decode/: https://github.com/probe-rs/probe-rs/pull/564;
- rust-embedded/cortex-m ::
  - /scb: derive serde, Hash, PartialOrd for VectActive behind gates/: https://github.com/rust-embedded/cortex-m/pull/363;
  - /Implement various interfaces for trace configuration/: https://github.com/rust-embedded/cortex-m/pull/342;
- rust-embedded/itm ::
  - /replace crate with itm-decode/: https://github.com/rust-embedded/itm/pull/41;
- rtic-rs/rtic-syntax ::
  - /improve error string if parse_binds is not set/: https://github.com/rtic-rs/rtic-syntax/pull/47.
- rtic-rs/cortex-m-rtic ::
  - /book=/=migration=/=v5: update init signature, fix example syntax/: https://github.com/rtic-rs/cortex-m-rtic/pull/480;
  - /book: detail import resolving for 0.6 migration/: https://github.com/rtic-rs/cortex-m-rtic/pull/479;
  - /book: update outdated required init signature/: https://github.com/rtic-rs/cortex-m-rtic/pull/478.

*** TODO Outline
 This paper is structured as follows
 - [[Introduction]] :: provides an introduction to Rust, RTIC, ARMv7-M hardware peripherals of interest, and the RTIC Scope project.
 - [[Previous work]] :: presents work previously done in the same domain, which this thesis builds upon.
 - [[Related work]] :: presents some tools similar to the features of RTIC Scope.
 - [[Theory]] :: covers the exploited ARM peripherals in detail, and what information is required to associate trace data to RTIC tasks.
 - [[Implementation]] :: covers the implementation of RTIC Scope and the ~itm~ crate.
 - [[Results]] ::
 - [[Discussion]] ::
 - [[Conclusions]] ::
 - [[Future work]] ::
 - Appendices ::

** TODO Implementation
This section covers the implementation of ~cargo-rtic-scope~, ~cortex-m-rtic-trace~, and ~rtic-scope-frontend-dummy~ of RTIC Scope and the implementation of ~itm~.
First of, what is dubbed the "recovery step" is covered after which the implementation is presented in a downstream manner: how
1. ~cortex-m-rtic-trace~ enables trace generation from =#[init]=, and how the =#[trace]= macro is applied;
2. the trace stream exfiltrates via ETB/TPIU;
3. ~cargo-rtic-scope~ reads the raw trace stream from the source;
4. ~itm~ decodes this stream into manageable Rust structures;
5. ~cargo-rtic-scope~ recovers RTIC metadata for the decoded trace stream; and
6. this resolved trace stream is forwarded to sinks.

*** The recovery step
# source file parsing, trace lookup maps
The ITM packet protocol allows us to trace both hardware and software tasks.
Hardware tasks are traced via exception trace packets.
These are emitted when an interrupt handler is entered, exited, or returned to from another interrupt handler that preempted it with a higher priority.
This packet contains two fields of information: the IRQ number of the associated interrupt handler, and whether the handler was entered, exited, or returned to.

Software tasks are traced via data trace value packets.
These are emitted when a watch address is written to, given that a DWT comparator is properly configured.
A watch address can be any address that the user code have access to.
This packet contains three fields of information: the DWT comparator number that registered the match, whether the watch address was written to or read, and the value written to or read from the watch address.

These two packets cannot be associated to RTIC tasks on their own.
The recovery step of RTIC Scope must thus generate host-side lookup maps that map IRQ numbers to hardware tasks and data trace values and DWT comparator numbers to software tasks.
These translation maps are aptly named the =recovery::SoftwareMap= and =recovery::HardwareMap=.
Together they constitute the information available in a =recovery::TraceLookupMaps=.

**** Generating the =recovery::HardwareMap=
In order to generate a =recovery::HardwareMap= the RTIC application declaration must be parsed.
This is done when the RTIC app is built via =cargo build= when the =#[rtic::app(..)]= macro is expanded by help of ~rtic_syntax::parse{,2}~ functions which yelds yields (among other) a =rtic_syntax::App=.
This structure is not communicated to RTIC Scope which means that the RTIC app must be parsed one additional time.

In order to generate a =rtic_syntax::App= for recovery purposes =rtic_syntax::parse2= must be called directly with the arguments of =#[rtic::app(..)]= and with the input to the macro.
For example, in [[lst:recovery-example]], =device = stm32f4::stm32f401= is the macro arguments, and =mod app { ... }= is the macro input.
#+CAPTION: Example RTIC application declaration for execution on the STMicroelectronics STM32 NUCLEO-F401RE.
#+NAME: lst:recovery-example
#+begin_src rust
  #[rtic::app(device = stm32f4::stm32f401)]
  mod app {
      #[shared]
      struct Shared {}

      #[local]
      struct Local {}

      #[init]
      fn init(mut ctx: init::Context) -> (Shared, Local, init::Monotonics) {
          // ...
          (Shared {}, Local {}, init::Monotonics())
      }

      #[task(binds = SysTick)]
      fn task1(_: task1::Context) {
          // ...
      }

      #[task(binds = EXTI1)]
      fn task2(_: task2::Context) {
          // ...
      }
  }
#+end_src
However, these \glspl{AST} are not readily available without further preparatory work; they must first be extracted from the source file containing [[lst:recovery-example]].


To find the source file, the RTIC app must first be built. This is done via =build::CargoWrapper::new= [fn:recovery-build] which intercepts the output of =cargo build --message-format=json-diagnostic-rendered-ansi= by help of the =cargo_metadata= crate.
This output contains the absolute path to the source file that contains [[lst:recovery-example]].

With the source file readily available it is parsed as a \gls{tokenstream} by skipping \glspl{token} until =#[rtic::app]= is found, after which the =rtic_syntax= parsing explained above is done.

At this point we have the necessary =rtic_syntax::App= structure to continue: =rtic_syntax::App::hardware_tasks= is a collection of =rtic_syntax::HardwareTask= that lists what interrupt handler each hardware task is bound to via the =binds= argument in =#[task(binds = ...)]=.
After parsing [[lst:recovery-example]], =hardware_tasks= contains [fn:: abstracted for brevity.]
#+begin_export latex
$$
\langle \text{\texttt{app::task1} binds to \texttt{SysTick}} \rangle, \langle \text{\texttt{app::task2} binds to \texttt{EXTI1}} \rangle
$$
#+end_export
Of these, the =app::task1= bind is considered known, and the =app::task2= bind is considered unknown.
A known bind is one that no more recovery work must be applied on.
This follows from the specification of the exception trace packet: [[tbl:irqns]] enumerates all numbers that can be in the packet's IRQ field.
All $\text{IRQn} < 16$ are common to all ARMv7-M targets, the name of which can be directly mapped to the RTIC task that binds the IRQ name.
All $\text{IRQn} \geq 16$ on the other hand, are not common to all ARMv7-M, and are thus treated as platform-specific because the labels (specified via =#[task(binds = ...)]=) are unknown.
Additional recovery must be done to find these labels.

#+CAPTION: ARMv7-M Exception/IRQ numbers and names. Copied from (cite:arm-rm; Table B1-4).
#+NAME: tbl:irqns
#+ATTR_HTML: :rules all
| Exception number | Exception name/label   |
|------------------+------------------------|
|                1 | Reset                  |
|                2 | NMI                    |
|                3 | HardFault              |
|                4 | MemManage              |
|                5 | BusFault               |
|             7-10 | Reserved               |
|               11 | SVCall                 |
|               12 | DebugMonitor           |
|               13 | Reserved               |
|               14 | PendSV                 |
|               15 | SysTick                |
|               16 | External interrupt 0   |
|                . | .                      |
|                . | .                      |
|                . | .                      |
|         16 + $N$ | External interrupt $N$ |
|------------------+------------------------|

For any RTIC application, the labels are available in the =PAC::Interrupt= enum. For [[lst:recovery-example]], =PAC= is =stm32::stm32f401=.
An example declaration of such an enum can be seen in [[lst:pac-interrupt-example]].
#+NAME: lst:pac-interrupt-example
#+CAPTION: Example declaration of a =PAC::Interrupt= enum. Left-hand side of =Interrupt= is the IRQ label; right-hand is $N$ in [[tbl:irqns]].
#+begin_src rust
  pub mod PAC {
      #[derive(Debug)]
      #[repr(u16)]
      pub enum Interrupt {
          PVD = 1,
          EXTI0 = 6,
          EXTI1 = 7,
          // ...
      }

      unsafe impl cortex_m::interrupt::InterruptNumber for Interrupt {
          #[inline(always)]
          fn number(self) -> u16 {
              self as u16
          }
      }
  }
#+end_src
By finding the label used in =#[task(bind = ...)]= in =PAC::Interrupt= we find what enum constructor to use.
With the enum in hand, we construct it and get the IRQ number offset $N$ via
#+begin_src rust
  let label = PAC::Interrupt::EXTI1;
  assert_eq!(label.number(), 7);
#+end_src
To get the IRQ number of this unknown bind we simly sum it with $16$, as documented by [[tbl:irqns]]:
#+begin_src rust
  let irq_nr = label.number() + 16;
  assert_eq!(irq_nr, 23);
#+end_src
This process is unfortunately non-trivial: Rust does not have dynamic programming features and an ideal evaluation function of
#+begin_src rust
  fn resolve_irq_nr(label: &str) -> u16 {
      quote!(PAC::Interrupt::$label).eval().number() + 16;
  }
#+end_src
is not realizable.

Enter =recovery::resolve_int_nrs=: given a list of labels, the function
1. extracts an embedded file tree constituting a crate to the RTIC application's ~target/cargo-rtic-trace-libadhoc~;
2. adds a user-specified crate dependency for the PAC in ~Cargo.toml~;
3. for each label: adds a non-mangled function with the same name as the label that returns the associated IRQ number offset, $N$ (for [[lst:recovery-example]] the generated code can be seen in [[lst:resolve_int_nrs-example]]);
   #+begin_src rust
     #[no_mangle]
     pub extern fn EXTI1() -> u16 {
         Interrupt::EXTI0.number()
     }
   #+end_src
4. builds the crate as a cdylib[fn:cdylib];
5. loads the library into memory;
6. for each label: calls the associated function in the library to get the offset $N$ and sums it with 16; and
7. collects the results.
This collection then merges with the collection of known maps.

# TODO, explain where user-supplied information comes from.

**** TODO Generating the =recovery::SoftwareMap=

*** Resolving software task names
  The =ExceptionTrace= does not give us all the information we need.
  Instead, a [[#DWT]] unit can be employed to emit =DataTraceValue= packets on software task enter and exit.
  Via this approach, each software task is given a unique ID and code is injected (either by the =rtic::app= macro or by the end-user themselves) to write this unique ID at the start and end of the software task.
  The emitted =DataTraceValue= packets are then analysed by the host application, which maintains a state of which software task is currenly running.[fn:dwt-running-bit]
  The RTIC application source is then parsed to associate =DataTraceValue= payloads back to their software tasks.

  In comparison to hardware tasks, which are practically traced for free, software tasks can be traced at the cost of a few register writes and a dedicated DWT unit.
*** Decoding the ITM packet stream
Before the trace stream can be processed, the serialized stream must be decoded into workable Rust structures.
This is done via /itm-decode/ which
1. pattern matches the packet header;
2. checks if the payload is of the expected size; and
3. constructs the relevant structure.
If the packet cannot be decoded, an error structure is instead constructed, detailing why the packet is incorrect.
An erroneous packet can be received if the connection between embedded target and host system is not configured properly (e.g. baud-rate mismatch), or if the target itself does not adhere to the ITM packet protocol specification.

Additionally, itm-decode generates an absolute ISO timestamp from the relative timestamps in the protocol from a starting point and groups the relevant packets to this timestamp.

# TODO include a figure of the control flow
# TODO include reference to the library.
*** Summary
# TODO draw a tikz image block diagram of the targets' peripherals, going through an itm intermediate, into carg-rtic-scope, and when into file and frontends.

** TODO Results
*** Using RTIC Scope
From an end-user perspective RTIC Scope offers a "batteries-included" toolset that enables great insight into a target RTIC applications,
provided that a small set of limitations are adhered to and specific metadata is added to the application crate in question.
To install RTIC Scope, an end-user executes
#+begin_src shell
  $ cargo install cargo-rtic-scope
  $ cargo install rtic-scope-frontend-dummy
#+end_src
and adds the following metadata to their RTIC application's ~Cargo.toml~:
#+begin_src toml
  [package.metadata.rtic-scope]
  # necessary information for RTIC metadata recovery
  pac_name = "stm32f4"
  pac_features = ["stm32f401"]
  pac_version = "0.13"
  interrupt_path = "stm32f4::stm32f401::Interrupt"

  # ITM/DWT/TPIU parameters
  tpiu_freq = 16000000
  tpiu_baud = 115200
  dwt_enter_id = 1
  dwt_exit_id = 2
  lts_prescaler = 1

  # Whether it is expected that the target generates packets that do not adhere to the ITM standard.
  # For debugging purposes.
  expect_malformed = true
#+end_src

# TODO document cortex-m-rtic-trace usage

** TODO Discussion
*** Tracing overhead with RTIC Scope
[[https://developer.arm.com/documentation/102119/0200/Can-trace-capture-affect-a-system-][ARM's /Understanding Trace/, $7]], states that:
#+begin_quote
Except for the power that is consumed by the system trace components,
trace is almost entirely non-invasive. This means that performing trace
generation and collection does not influence the wider system.
#+end_quote

The target-side code of RTIC Scope itself has a negligible performance impact during execution:
- the ITM/DWT/TPIU units need only be configured once in =#[init]= or during some other preparatory stage; and
- when software tasks are traced, a =u8= variable write must be done when entering and exiting the task.

The performance of the host-side ~cargo-rtic-scope~ and ~rtic-scope-frontend-dummy~ have not been measured.

# TODO DWT unit consumption
*** TODO Conclusions
*** TODO Future work

\printbibliography
\appendices

** TODO Application to a non-linear control system
 # The results of the R7014E-alike course

* Footnotes
[fn:recovery-build] A positive side-effect of this step is that the RTIC Scope user does not have to manually call =cargo build= before =cargo rtic-scope trace=.

[fn:2] Additional tasks could for example include: handling firmware updates over the air. # TODO more examples?
[fn:1] The program that executes on the embedded system when initialization has concluded. In some contexts also referred to as the "main loop".

[fn:cargo-cdylibs] See
https://docs.rs/cargo/0.52.0/cargo/core/compiler/struct.Compilation.html#structfield.cdylibs.

[fn:cdylib] A cdylib crate is a crate that specifies =crate_type = ["cdylib"]=.
Upon building the crate a dynamic library (a shared object file) that targets the stable C ABI is generated.
Additionally, it is trivial to find the file location of cdylibs with cargo[fn:cargo-cdylibs].
This is not the case with dylibs that instead target the unstable Rust ABI.
The only way to generate a shared object file is by building a dylib or a cdylib.

[fn:dwt-running-bit] Alternatively, one bit in the =DataTraceValue= payload can denote whether a task was entered or exited.

[fn:cargo] See https://crates.io/crates/cargo.

[fn:rtic-syntax] See https://crates.io/crates/rtic-syntax.

[fn:decoder] Based upon the existing works of ~itm-tools~[fn:itm-tools].

[fn:memory-lanes] https://github.com/rtic-rs/rfcs/issues/31 discusses the RTIC-abstraction of RTT and similar peripherals to "memory lanes".

[fn:itm-tools] See https://github.com/japaric/itm-tools.

[fn:cli] Command-line interface.
